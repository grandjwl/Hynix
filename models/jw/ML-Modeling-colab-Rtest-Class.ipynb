{"cells":[{"cell_type":"markdown","id":"e958daf9","metadata":{"id":"e958daf9"},"source":["# 데이터 업로드"]},{"cell_type":"code","execution_count":1,"id":"8fb71e6e","metadata":{"id":"8fb71e6e","executionInfo":{"status":"ok","timestamp":1692332971102,"user_tz":-540,"elapsed":2116,"user":{"displayName":"이정우","userId":"10083734097573968476"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import os\n","\n","import pickle\n","import shutil\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","current_path = os.getcwd()\n","print(current_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OP6f5vc69XZK","executionInfo":{"status":"ok","timestamp":1692332990986,"user_tz":-540,"elapsed":19888,"user":{"displayName":"이정우","userId":"10083734097573968476"}},"outputId":"46fb2a35-16ae-4bdd-d6c2-87ae42b3f7cc"},"id":"OP6f5vc69XZK","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content\n"]}]},{"cell_type":"code","execution_count":3,"id":"94abfb0d","metadata":{"scrolled":true,"id":"94abfb0d","executionInfo":{"status":"ok","timestamp":1692332996275,"user_tz":-540,"elapsed":5291,"user":{"displayName":"이정우","userId":"10083734097573968476"}}},"outputs":[],"source":["path=r'/content/drive/MyDrive/기업프로젝트/머신러닝/데이터/testset.csv'\n","df=pd.read_csv(path,index_col=0)\n","path=r'/content/drive/MyDrive/기업프로젝트/머신러닝/데이터/Hynix_train2.csv'\n","df2=pd.read_csv(path, index_col=0)\n","\n","from sklearn.model_selection import train_test_split\n","train,test= train_test_split(df2, test_size=0.2,random_state=1234)\n","train,valid= train_test_split(train, test_size=0.25,random_state=1234)"]},{"cell_type":"markdown","id":"38939e4e","metadata":{"id":"38939e4e"},"source":["#클래스화"]},{"cell_type":"code","execution_count":4,"id":"b90418c6","metadata":{"id":"b90418c6","executionInfo":{"status":"ok","timestamp":1692333074790,"user_tz":-540,"elapsed":631,"user":{"displayName":"이정우","userId":"10083734097573968476"}}},"outputs":[],"source":["class Preprocessor :\n","    default_path = '/content/drive/MyDrive/기업프로젝트/머신러닝/데이터/Pickle'\n","\n","    def __init__(self):\n","        pass\n","\n","    def time_preprocessing(self,df):\n","        df.set_index(keys=\"ID\", inplace=True)\n","        df.drop(columns=\"x204\",inplace=True)\n","        for idx,col in enumerate(df.columns.to_list()[188:1454]):\n","            if df[col].dtype == \"object\":\n","                df[col] = pd.to_datetime(df[col])\n","        datatmp = df.columns.to_list()[188:1454]\n","        ts_data = df.select_dtypes(\"datetime\")\n","        for idx in ts_data.index:\n","            ts_data.sort_values(by=idx,axis=1, inplace=True)\n","\n","        columns = ts_data.columns\n","        num_columns = len(columns)\n","        for i in range(1, num_columns):\n","            column_diff = pd.to_datetime(df.iloc[:, i]) - pd.to_datetime(ts_data.iloc[:, i-1])\n","            column_diff_hours = column_diff.dt.total_seconds() / 3600\n","            ts_data.iloc[:, i] = column_diff_hours\n","\n","        for i in range(len(ts_data.columns)-1):\n","            ts_data.iloc[:, i] = ts_data.iloc[:, i+1]\n","        result = []\n","        for idx,col in enumerate(datatmp):\n","            if df[col].dtype == \"<M8[ns]\":\n","                cur = int(col[1:])\n","                i = idx\n","                tmp = []\n","                while i > 0:\n","                    i -= 1\n","                    next = datatmp[i]\n","                    if df[next].dtype == \"<M8[ns]\":\n","                        break\n","                    else:\n","                        tmp.append(next)\n","                        tmp.sort()\n","                result.append((col,tmp))\n","        ts_final = []\n","        for elem in ts_data.columns:\n","            for target,content in result:\n","                if elem == target:\n","                    ts_final.extend(content)\n","                    ts_final.append(target)\n","\n","        ts_final = df[ts_final]\n","        front = df.loc[:,:\"x193\"]\n","        back = df.loc[:,\"x1461\":]\n","        final = pd.concat([front, ts_final, back], axis = 1)\n","        ts_data.drop(columns=ts_data.columns[-1], inplace=True)\n","\n","        for col in ts_data.columns:\n","            if col in final.columns:\n","                final[col] = ts_data[col]\n","        final.drop(['x197'], axis=1, inplace=True)\n","        df = final\n","        return df\n","\n","\n","\n","\n","\n","    def na_ratio_preprocessing_train(self,train):\n","        na_percentage = train.isna().sum() / len(train)\n","        high_na_columns = na_percentage[na_percentage >= 0.9].index\n","        train=train.drop(high_na_columns, axis=1,inplace=False)\n","        with open(Preprocessor.default_path + '/high_na_columns.pkl', 'wb') as f:\n","          pickle.dump(high_na_columns, f)\n","        return train\n","\n","    def na_ratio_preprocessing_Rtest(self,Rtest):\n","        with open(Preprocessor.default_path + '/high_na_columns.pkl', 'rb') as f:\n","          high_na_columns = pickle.load(f)\n","        Rtest=Rtest.drop(high_na_columns, axis=1,inplace=False)\n","        return Rtest\n","\n","\n","\n","\n","\n","    def correlation_preprocessing_train(self,train):\n","        numeric_columns = train.select_dtypes(include=['int64', 'float64'])\n","        correlation_with_target = numeric_columns.corr()['Y']\n","        columns_with_low_correlation = correlation_with_target[correlation_with_target.abs() < 0.04].index\n","        train.drop(columns_with_low_correlation, axis=1, inplace=True)\n","        with open(Preprocessor.default_path+'/columns_with_low_correlation.pkl', 'wb') as f:\n","            pickle.dump(columns_with_low_correlation, f)\n","        return train\n","\n","    def correlation_preprocessing_Rtest(self,Rtest):\n","        with open(Preprocessor.default_path+'/columns_with_low_correlation.pkl', 'rb') as f:\n","          columns_with_low_correlation = pickle.load(f)\n","        Rtest.drop(columns_with_low_correlation, axis=1, inplace=True)\n","        return Rtest\n","\n","\n","\n","\n","\n","    def replace_outliers_median_preprocessing_train(self,train , threshold=1.5):\n","        all_lower_bound={}\n","        all_upper_bound={}\n","        all_col_median={}\n","        for col in train.columns:\n","            Q1 = train[col].quantile(0.25)\n","            Q3 = train[col].quantile(0.75)\n","            IQR = Q3 - Q1\n","            lower_bound = Q1 - threshold * IQR\n","            all_lower_bound[col]=lower_bound\n","            upper_bound = Q3 + threshold * IQR\n","            all_upper_bound[col]=upper_bound\n","\n","            train_outliers = train[col][(train[col] < lower_bound) | (train[col] > upper_bound)]\n","            col_median = train[col].median()\n","            all_col_median[col]=col_median\n","            train.loc[train_outliers.index, col] = col_median\n","        with open(Preprocessor.default_path+'/all_lower_bound.pkl', 'wb') as f:\n","            pickle.dump(all_lower_bound, f)\n","        with open(Preprocessor.default_path+'/all_upper_bound.pkl', 'wb') as f:\n","            pickle.dump(all_upper_bound, f)\n","        with open(Preprocessor.default_path+'/all_col_median.pkl', 'wb') as f:\n","            pickle.dump(all_col_median, f)\n","        return train\n","\n","    def replace_outliers_median_preprocessing_Rtest(self,Rtest, threshold=1.5):\n","        with open(Preprocessor.default_path+'/all_lower_bound.pkl', 'rb') as f:\n","            all_lower_bound = pickle.load(f)\n","        with open(Preprocessor.default_path+'/all_upper_bound.pkl', 'rb') as f:\n","            all_upper_bound = pickle.load(f)\n","        with open(Preprocessor.default_path+'/all_col_median.pkl', 'rb') as f:\n","            all_col_median = pickle.load(f)\n","\n","        for col in Rtest.columns:\n","            Rtest_outliers = Rtest[col][(Rtest[col] < all_lower_bound[col]) | (Rtest[col] > all_upper_bound[col])]\n","            Rtest.loc[Rtest_outliers.index, col] = all_col_median[col]\n","        return Rtest\n","\n","\n","\n","\n","\n","\n","    def fillna_mean_preprocessing_train(self,train):\n","        col_means = {}\n","        use_col = []\n","\n","        for col in train.columns:\n","            col_mean = train[col][~train[col].isnull()].mean()\n","            if pd.notna(col_mean):\n","                train[col].fillna(col_mean, inplace=True)\n","                use_col.append(col)\n","                if train[col].nunique() == 1:\n","                  use_col.remove(col)\n","            col_means[col] = col_mean\n","        with open(Preprocessor.default_path+'/col_means.pkl', 'wb') as f:\n","            pickle.dump(col_means, f)\n","        with open(Preprocessor.default_path+'/use_col.pkl', 'wb') as f:\n","            pickle.dump(use_col, f)\n","        return train[use_col]\n","\n","    def fillna_mean_preprocessing_Rtest(self,Rtest):\n","        with open(Preprocessor.default_path+'/col_means.pkl', 'rb') as f:\n","            col_means = pickle.load(f)\n","        with open(Preprocessor.default_path+'/use_col.pkl', 'rb') as f:\n","            use_col = pickle.load(f)\n","\n","        for col in Rtest.columns:\n","            if col in use_col:\n","                Rtest[col].fillna(col_means[col], inplace=True)\n","        return Rtest[use_col]\n","\n","\n","\n","\n","\n","    def scale_preprocessing_train(self,train):\n","        scaler = MinMaxScaler()\n","        strain = scaler.fit_transform(train)\n","        with open(Preprocessor.default_path+'/scaler.pkl', 'wb') as f:\n","          pickle.dump(scaler, f)\n","        train = pd.DataFrame(strain, columns=train.columns,index=train.index)\n","        return train\n","\n","    def scale_preprocessing_Rtest(self,Rtest):\n","        with open(Preprocessor.default_path+'/scaler.pkl', 'rb') as f:\n","            scaler = pickle.load(f)\n","        sRtest = scaler.transform(Rtest)\n","        Rtest = pd.DataFrame(sRtest, columns=Rtest.columns,index=Rtest.index)\n","        return Rtest\n","\n","\n","\n","\n","\n","    def preprocessing_train(self, train):\n","      train = self.na_ratio_preprocessing_train(train)\n","      train = self.correlation_preprocessing_train(train)\n","      train = train.drop(columns=['Y'])\n","      train = self.replace_outliers_median_preprocessing_train(train)\n","      train = self.fillna_mean_preprocessing_train(train)\n","      train = self.scale_preprocessing_train(train)\n","      return train\n","\n","\n","\n","\n","    def preprocessing_Rtest(self,df):\n","        Rtest = self.time_preprocessing(df)\n","        Rtest = self.na_ratio_preprocessing_Rtest(Rtest)\n","        Rtest = self.correlation_preprocessing_Rtest(Rtest)\n","        Rtest = self.replace_outliers_median_preprocessing_Rtest(Rtest)\n","        Rtest = self.fillna_mean_preprocessing_Rtest(Rtest)\n","        Rtest = self.scale_preprocessing_Rtest(Rtest)\n","        return Rtest"]},{"cell_type":"code","source":["# preprocess = Preprocessor()\n","# default_path = '/content/drive/MyDrive/기업프로젝트/머신러닝/데이터/Pickle/'\n","# with open(default_path+\"Preprocessor\", \"wb\") as f:\n","#     pickle.dump(preprocess, f)"],"metadata":{"id":"3cr_zHJjQ67b","executionInfo":{"status":"ok","timestamp":1692333171620,"user_tz":-540,"elapsed":331,"user":{"displayName":"이정우","userId":"10083734097573968476"}}},"id":"3cr_zHJjQ67b","execution_count":6,"outputs":[]},{"cell_type":"code","source":["default_path = '/content/drive/MyDrive/기업프로젝트/머신러닝/데이터/Pickle/'\n","with open(default_path+\"Preprocessor\", \"rb\") as f:\n","     preprocess = pickle.load(f)"],"metadata":{"id":"blpmtrTuQ6-m"},"id":"blpmtrTuQ6-m","execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = preprocess.preprocessing_train(train)"],"metadata":{"id":"33kGJrO0C5NJ"},"id":"33kGJrO0C5NJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["Rtest = preprocess.preprocessing_Rtest(df)"],"metadata":{"id":"a3fA4P5hDBwi"},"id":"a3fA4P5hDBwi","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"992d14b4","metadata":{"id":"992d14b4"},"source":["# 모델 예측 결과"]},{"cell_type":"code","source":["best_model = load_model('/content/drive/MyDrive/기업프로젝트/머신러닝/데이터/ML_best_model')\n","predictions = predict_model(best_model, data=Rtest)['prediction_label']*100"],"metadata":{"id":"91E4LnnqgGAW"},"id":"91E4LnnqgGAW","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"hynix","language":"python","name":"hynix"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"colab":{"provenance":[{"file_id":"1F7IbHQzpMfasq2-DEinrV9Vj6GPhR1ig","timestamp":1688884519878}],"machine_shape":"hm"}},"nbformat":4,"nbformat_minor":5}